{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c98a20-7952-46df-bcb4-b79bce3081e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b280e4d8-cb84-46ec-9413-3573a9291cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import duckdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "\n",
    "from src.data import utils as du\n",
    "import src.locations as loc\n",
    "from src.config import settings, datasets\n",
    "\n",
    "DATA_FULL = du.build_alias_path_dict(Path(loc.DATA_SUBDIR['processed']) / 'company-matching__full')\n",
    "DATA_100K = du.build_alias_path_dict(Path(loc.DATA_SUBDIR['processed']) / 'company-matching__06-26-23_11-40-51')\n",
    "PRED_PATH = Path(loc.DATA_SUBDIR['processed']) / 'company-matching__full' / 'predictions.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6672ef2-ddbc-442c-94f9-c03e6e42f84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/io/sql.py:1410: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  meta = MetaData(self.connectable, schema=schema)\n"
     ]
    }
   ],
   "source": [
    "df_ch = du.get_company_data(\n",
    "    cols=datasets['\"companieshouse\".\"companies\"'][\"cols\"],\n",
    "    dataset='\"companieshouse\".\"companies\"',\n",
    "    where=datasets['\"companieshouse\".\"companies\"'][\"where\"],\n",
    "    sample=100_000,\n",
    ")\n",
    "df_dh = du.get_company_data(\n",
    "    cols=datasets['\"dit\".\"data_hub__companies\"'][\"cols\"],\n",
    "    dataset='\"dit\".\"data_hub__companies\"',\n",
    "    where=datasets['\"dit\".\"data_hub__companies\"'][\"where\"],\n",
    "    sample=100_000,\n",
    ")\n",
    "df_ex = du.get_company_data(\n",
    "    cols=datasets['\"hmrc\".\"trade__exporters\"'][\"cols\"],\n",
    "    dataset='\"hmrc\".\"trade__exporters\"',\n",
    "    where=datasets['\"hmrc\".\"trade__exporters\"'][\"where\"],\n",
    "    sample=100_000,\n",
    ")\n",
    "df_ew = du.get_company_data(\n",
    "    cols=datasets['\"dit\".\"export_wins__wins_dataset\"'][\"cols\"],\n",
    "    dataset='\"dit\".\"export_wins__wins_dataset\"',\n",
    "    where=datasets['\"dit\".\"export_wins__wins_dataset\"'][\"where\"],\n",
    "    sample=100_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdb4ce1-e3fc-4fbf-afa8-8b9a4da4d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = duckdb.connect()\n",
    "\n",
    "connection.query(f\"\"\"\n",
    "    create table companieshouse_companies as select * from df_ch;\n",
    "    create table dit_data_hub__companies as select * from df_dh;\n",
    "    create table hmrc_trade__exporters as select * from df_ex;\n",
    "    create table dit_export_wins__wins_dataset as select * from df_ew;\n",
    "\"\"\")\n",
    "\n",
    "json_raw = mlflow.artifacts.load_text(\n",
    "    artifact_uri=\"runs:/22ce217706c54650ac34f59cb6a45960/model/companies_matching_model.json\"\n",
    ")\n",
    "json_settings = json.loads(json_raw)\n",
    "\n",
    "linker = DuckDBLinker(\n",
    "    list(DATA_100K.values()),\n",
    "    settings_dict=settings,\n",
    "    connection=connection,\n",
    "    input_table_aliases=list(DATA_100K.keys()),\n",
    ")\n",
    "linker.load_model(json_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8fd7d1-f14c-493f-b11e-ca0402eedb68",
   "metadata": {},
   "source": [
    "I've had a lot of problems with the clsutering parts of Splink, but I wondered if I could use the predictions frame similarly to the lookup I made before.\n",
    "\n",
    "This notebook is to test that out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651fab8-340f-42fc-9659-d0a1cc9d12ae",
   "metadata": {},
   "source": [
    "## Production with predictions\n",
    "\n",
    "Using only the prediction dataframe we need:\n",
    "\n",
    "* (Dupes) For a given source and list of targets, all IDs that need to be joined on both sides, where the highest pairwise match prediction is the ONLY one that matches \n",
    "* (Deduped) As above, PLUS only the top match returned between each pair of tables\n",
    "\n",
    "Don't forget, because we link and dedupe we also have INTERNAL matches at play."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c398c-3a92-4e12-8042-9b88b03cc02b",
   "metadata": {},
   "source": [
    "## Production with clusters\n",
    "\n",
    "This is more or less lifted from WL_splink-test, with the exception that I've attached the raw data to the DuckDB to mimic the Postgres environment better.\n",
    "\n",
    "I don't think it's quite working as it was before -- the counts on dupe/dedupe come back suspiciously similar. I don't want to spend time fixing it when I think the future is predictions, so just be careful with the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a993333b-cd5a-4cf2-ac2a-5a8c33f40c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'comp_num_clean':\n",
      "    u values not fully trained\n",
      "Completed iteration 1, root rows count 27\n",
      "Completed iteration 2, root rows count 0\n"
     ]
    }
   ],
   "source": [
    "predictions = linker.predict(threshold_match_probability=.7)\n",
    "\n",
    "clusters = linker.cluster_pairwise_predictions_at_threshold(\n",
    "    predictions,\n",
    "    threshold_match_probability=.7,\n",
    "    pairwise_formatting=True,\n",
    "    filter_pairwise_format_for_clusters=False,\n",
    ")\n",
    "\n",
    "lookup = linker.query_sql(\n",
    "    f\"\"\"\n",
    "    select\n",
    "        source_dataset_l as source,\n",
    "        unique_id_l as source_id,\n",
    "        cluster_id_l as source_cluster,\n",
    "        source_dataset_r as target,\n",
    "        unique_id_r as target_id,\n",
    "        cluster_id_r as target_cluster,\n",
    "        match_probability\n",
    "    from\n",
    "        { clusters.physical_name }\n",
    "    union\n",
    "    select\n",
    "        source_dataset_r as source,\n",
    "        unique_id_r as source_id,\n",
    "        cluster_id_r as source_cluster,\n",
    "        source_dataset_l as target,\n",
    "        unique_id_l as target_id,\n",
    "        cluster_id_l as target_cluster,\n",
    "        match_probability\n",
    "    from\n",
    "        { clusters.physical_name }\n",
    "    \"\"\",\n",
    "    # output_type=\"splink_df\",\n",
    ")\n",
    "\n",
    "connection.query(f\"\"\"\n",
    "    create table lookup as select * from lookup;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78314ff2-3d1d-48b4-950e-414f8ba29fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "┌───────────┬───────────────────────────┬───────────────────────────┬─────────┐\n",
       "│ unique_id │          ch_name          │          dh_name          │ ew_name │\n",
       "│  varchar  │          varchar          │          varchar          │ varchar │\n",
       "├───────────┼───────────────────────────┼───────────────────────────┼─────────┤\n",
       "│ 02453212  │ ST HELENS CHAMBER LIMITED │ ST HELENS CHAMBER LIMITED │ NULL    │\n",
       "│ 07343391  │ EMPOWER ENERGY LIMITED    │ NULL                      │ NULL    │\n",
       "│ 07374749  │ AMBREY RISK LIMITED       │ NULL                      │ NULL    │\n",
       "│ 11109773  │ IONIAN PELLO TECH LIMITED │ IONIAN PELLO TECH LIMITED │ NULL    │\n",
       "│ 03478491  │ PREMIER PITCHES LIMITED   │ PREMIER PITCHES LIMITED   │ NULL    │\n",
       "└───────────┴───────────────────────────┴───────────────────────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_with_dupes = connection.sql(\"\"\"\n",
    "    select\n",
    "        ch.unique_id,\n",
    "        ch.company_name as ch_name,\n",
    "        dh.company_name as dh_name,\n",
    "        ew.company_name as ew_name\n",
    "    from (\n",
    "        select \n",
    "            *\n",
    "        from\n",
    "            lookup lookup\n",
    "        where\n",
    "            lookup.source = 'companieshouse_companies'\n",
    "            and lookup.target in (\n",
    "                'dit_data_hub__companies',\n",
    "                'dit_export_wins__wins_dataset'\n",
    "            )\n",
    "    ) lookup\n",
    "    right outer join companieshouse_companies ch on\n",
    "        lookup.source_id = ch.unique_id \n",
    "        and lookup.source = 'companieshouse_companies'\n",
    "    left join dit_data_hub__companies dh on\n",
    "        lookup.target_id = dh.unique_id \n",
    "        and lookup.target = 'dit_data_hub__companies'\n",
    "    left join dit_export_wins__wins_dataset ew on\n",
    "        lookup.target_id = ew.unique_id\n",
    "        and lookup.target = 'dit_export_wins__wins_dataset'\n",
    "\"\"\")\n",
    "\n",
    "join_with_dupes.df().shape\n",
    "connection.sql(\"select * from join_with_dupes limit 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b3c758-833a-436d-accf-4d2c33ebb0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "┌───────────┬────────────────────────────────────────────┬────────────────────────────────────────────┬─────────┐\n",
       "│ unique_id │                  ch_name                   │                  dh_name                   │ ew_name │\n",
       "│  varchar  │                  varchar                   │                  varchar                   │ varchar │\n",
       "├───────────┼────────────────────────────────────────────┼────────────────────────────────────────────┼─────────┤\n",
       "│ 11109773  │ IONIAN PELLO TECH LIMITED                  │ IONIAN PELLO TECH LIMITED                  │ NULL    │\n",
       "│ 02453212  │ ST HELENS CHAMBER LIMITED                  │ ST HELENS CHAMBER LIMITED                  │ NULL    │\n",
       "│ 03478491  │ PREMIER PITCHES LIMITED                    │ PREMIER PITCHES LIMITED                    │ NULL    │\n",
       "│ 08435515  │ THE ROYAL BUCKINGHAMSHIRE HOSPITAL LIMITED │ THE ROYAL BUCKINGHAMSHIRE HOSPITAL LIMITED │ NULL    │\n",
       "│ 07343391  │ EMPOWER ENERGY LIMITED                     │ NULL                                       │ NULL    │\n",
       "└───────────┴────────────────────────────────────────────┴────────────────────────────────────────────┴─────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_no_dupes = connection.sql(\"\"\"\n",
    "    select\n",
    "        ch.unique_id,\n",
    "        ch.company_name as ch_name,\n",
    "        dh.company_name as dh_name,\n",
    "        ew.company_name as ew_name\n",
    "    from (\n",
    "        select\n",
    "            source,\n",
    "            source_id,\n",
    "            array_agg(target) as target, \n",
    "            array_agg(target_id) as target_id\n",
    "        from (\n",
    "            select distinct on (\n",
    "                lookup.source_id, \n",
    "                lookup.target,\n",
    "                lookup.target_cluster\n",
    "            )\n",
    "                *\n",
    "            from\n",
    "                lookup lookup\n",
    "            where\n",
    "                lookup.source = 'companieshouse_companies'\n",
    "                and lookup.target in (\n",
    "                    'dit_data_hub__companies',\n",
    "                    'dit_export_wins__wins_dataset'\n",
    "                )\n",
    "            order by\n",
    "                lookup.source_id, \n",
    "                lookup.target,\n",
    "                lookup.target_cluster,\n",
    "                lookup.match_probability desc\n",
    "        ) lookup\n",
    "        where\n",
    "            lookup.source = 'companieshouse_companies'\n",
    "            and lookup.target in (\n",
    "                'dit_data_hub__companies',\n",
    "                'dit_export_wins__wins_dataset'\n",
    "            )\n",
    "        group by\n",
    "            source,\n",
    "            source_id\n",
    "    ) lookup\n",
    "    right join companieshouse_companies ch on\n",
    "        lookup.source_id = ch.unique_id \n",
    "        and lookup.source = 'companieshouse_companies'\n",
    "    left join dit_data_hub__companies dh on\n",
    "        array_has(lookup.target_id, dh.unique_id)\n",
    "        and array_has(lookup.target, 'dit_data_hub__companies')\n",
    "    left join dit_export_wins__wins_dataset ew on\n",
    "        array_has(lookup.target_id, ew.unique_id)\n",
    "        and array_has(lookup.target, 'dit_export_wins__wins_dataset')\n",
    "\"\"\")\n",
    "\n",
    "join_no_dupes.df().shape\n",
    "connection.sql(\"select * from join_no_dupes limit 5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_matching",
   "language": "python",
   "name": "company_matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
