{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123cf1dc-6310-4183-b12a-0879b927047b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://s3-eu-west-2.amazonaws.com/mirrors.notebook.uktrade.io/pypi/\n",
      "Collecting dwutils@ git+ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest\n",
      "  Cloning ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git (to revision latest) to /tmp/pip-install-e41jcl0i/dwutils_f4b1526497354be2bfcac10880e133e4\n",
      "  Running command git clone --filter=blob:none --quiet 'ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git' /tmp/pip-install-e41jcl0i/dwutils_f4b1526497354be2bfcac10880e133e4\n",
      "  Resolved ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git to commit 20144945565fe9e71c91311da3401156e12095ed\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gitpython in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.1.42)\n",
      "Requirement already satisfied: mlflow-skinny==2.10.* in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.10.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.12.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.0)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.9.7)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (15.0.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.0.20)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.34.58)\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.62.3)\n",
      "Requirement already satisfied: git-lfs-http-mirror in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.0.7)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.8.1)\n",
      "Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.0)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (6.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.25.3)\n",
      "Requirement already satisfied: pytz<2024 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (23.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (7.0.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from gitpython->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.0.11)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.58 in /opt/conda/lib/python3.9/site-packages (from boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.34.58)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.10.0)\n",
      "Requirement already satisfied: httpx>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.24.1)\n",
      "Requirement already satisfied: hypercorn>=0.14.3 in /opt/conda/lib/python3.9/site-packages (from git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.14.4)\n",
      "Requirement already satisfied: quart>=0.19.4 in /opt/conda/lib/python3.9/site-packages (from git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.19.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.12.25)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.9/site-packages (from pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.35.0,>=1.34.58->boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.26.18)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (5.0.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.17.3)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.3.0)\n",
      "Requirement already satisfied: h11 in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.14.0)\n",
      "Requirement already satisfied: h2>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.1.0)\n",
      "Requirement already satisfied: priority in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.16.0)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (23.2.1)\n",
      "Requirement already satisfied: blinker>=1.6 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.7.0)\n",
      "Requirement already satisfied: flask>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.2)\n",
      "Requirement already satisfied: itsdangerous in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.1.3)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.3)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/conda/lib/python3.9/site-packages (from h2>=3.1.0->hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/conda/lib/python3.9/site-packages (from h2>=3.1.0->hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.0.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.9/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dwutils@git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c76d233-7a6a-4d82-abd0-3ba75343de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3912d8f-6c0c-4767-bd6d-1af8339b9605",
   "metadata": {},
   "source": [
    "# Massive connected components\n",
    "\n",
    "Connected components crashes on 90m probabilities. We need to be able to handle that and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f280b4-811c-48b9-8316-87c5414b41a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring unparsable config /home/jovyan/company-matching/pyproject.toml\n",
      "ignoring unparsable config /home/jovyan/company-matching/pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "import cmf\n",
    "from cmf import clean\n",
    "from cmf.clean import steps\n",
    "from cmf.data.utils import sqa_profiled\n",
    "from cmf.dedupers import NaiveDeduper\n",
    "from cmf.helpers import cleaner, cleaners, selector\n",
    "from cmf.data.results import ClusterResults, ProbabilityResults\n",
    "\n",
    "import logging\n",
    "\n",
    "from dwutils import s3\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pyarrow as pa\n",
    "import rustworkx as rx\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "def create_cmf_pipelines_logger() -> logging.Logger:\n",
    "    pipeline_logger = logging.getLogger(\"cmf_pipelines\")\n",
    "    logic_logger = logging.getLogger(\"cmf_logic\")\n",
    "\n",
    "    pipeline_logger.setLevel(logging.INFO)\n",
    "    logic_logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s: %(levelname)s] %(name)s %(module)s: %(message)s\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    pipeline_logger.addHandler(handler)\n",
    "    logic_logger.addHandler(handler)\n",
    "\n",
    "    return pipeline_logger\n",
    "\n",
    "\n",
    "logger = create_cmf_pipelines_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d431277-3fee-46b7-bdbf-5944e9a750c4",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e50c7d-107d-43e2-88ec-c184f2d5a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NAME = \"naive_hmrc_exports_v1\"\n",
    "_SOURCE = \"hmrc.trade__exporters\"\n",
    "\n",
    "\n",
    "def _query(limit: Optional[int] = None) -> DataFrame:\n",
    "    \"\"\"Select data.\"\"\"\n",
    "\n",
    "    exp_selector = selector(\n",
    "        table=_SOURCE,\n",
    "        fields=[\"company_name\", \"postcode\"],\n",
    "    )\n",
    "\n",
    "    exp_raw = cmf.query(selector=exp_selector, return_type=\"pandas\", limit=limit)\n",
    "\n",
    "    logger.info(\n",
    "        \"Data retrieved successfully with %s unique datapoints\",\n",
    "        exp_raw.data_sha1.nunique(),\n",
    "    )\n",
    "\n",
    "    return exp_raw\n",
    "\n",
    "\n",
    "def _process(raw: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean data.\"\"\"\n",
    "\n",
    "    clean_exp = cleaners(\n",
    "        cleaner(clean.company_name, {\"column\": \"hmrc_trade__exporters_company_name\"}),\n",
    "        cleaner(clean.postcode, {\"column\": \"hmrc_trade__exporters_postcode\"}),\n",
    "    )\n",
    "\n",
    "    exp_clean = cmf.process(raw, clean_exp)\n",
    "\n",
    "    logger.info(\"Data cleaned successfully\")\n",
    "\n",
    "    return exp_clean\n",
    "\n",
    "\n",
    "def _deduplicate(clean: DataFrame) -> ProbabilityResults:\n",
    "    \"\"\"Deduplicate data.\"\"\"\n",
    "\n",
    "    exp_naive_deduper = cmf.make_deduper(\n",
    "        dedupe_run_name=_NAME,\n",
    "        description=\"Basic cleaning of name and postcode.\",\n",
    "        deduper=NaiveDeduper,\n",
    "        deduper_settings={\n",
    "            \"id\": \"data_sha1\",\n",
    "            \"unique_fields\": [\n",
    "                \"hmrc_trade__exporters_company_name\",\n",
    "                \"hmrc_trade__exporters_postcode\",\n",
    "            ],\n",
    "        },\n",
    "        data=clean,\n",
    "        data_source=_SOURCE,\n",
    "    )\n",
    "\n",
    "    exp_deduped = exp_naive_deduper()\n",
    "\n",
    "    logger.info(\n",
    "        \"Data deduplicated successfully. %s probabilities generated\",\n",
    "        exp_deduped.dataframe.shape[0],\n",
    "    )\n",
    "\n",
    "    return exp_deduped\n",
    "\n",
    "\n",
    "def _cluster(deduped: ProbabilityResults, clean: DataFrame) -> ClusterResults:\n",
    "    \"\"\"Resolve probabilities to clusters.\"\"\"\n",
    "    exp_clusters = cmf.to_clusters(clean, results=deduped, key=\"data_sha1\", threshold=1)\n",
    "\n",
    "    logger.info(\n",
    "        \"Clusters resolved successfully. %s clusters generated\",\n",
    "        exp_clusters.dataframe.parent.nunique(),\n",
    "    )\n",
    "\n",
    "    return exp_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bea25be-9933-4310-89b5-486d4a8e820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-12 11:26:40,074: INFO] cmf_pipelines 2290665410: Data retrieved successfully with 300000 unique datapoints\n",
      "[2024-03-12 11:26:43,184: INFO] cmf_pipelines 2290665410: Data cleaned successfully\n",
      "[2024-03-12 11:26:44,519: INFO] cmf_pipelines 2290665410: Data deduplicated successfully. 567484 probabilities generated\n",
      "[2024-03-12 11:26:47,066: INFO] cmf_pipelines 2290665410: Clusters resolved successfully. 109616 clusters generated\n"
     ]
    }
   ],
   "source": [
    "ew_raw = _query(limit=300_000)\n",
    "ew_clean = _process(raw=ew_raw)\n",
    "ew_deduped = _deduplicate(clean=ew_clean)\n",
    "ew_clusters = _cluster(deduped=ew_deduped, clean=ew_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d7549-7643-4bce-8aab-91954a2e67cf",
   "metadata": {},
   "source": [
    "## Playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5a194b2-0168-4f4a-849d-08e552b9d311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3793000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count\n",
       "0  3793000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dwutils import db\n",
    "\n",
    "db.query(f\"select count(*) from {_SOURCE};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af98ab-44ea-40f9-8485-640f8b684a0f",
   "metadata": {},
   "source": [
    "For 567,484 probabilities using the `WriteOnlyMapped` methodology.\n",
    "\n",
    "* 394 seconds at 500k batch size\n",
    "* 585 seconds at 250k batch size\n",
    "    * `execute` and `_emit_insert_statements` are like 400s of that\n",
    "    * 390 on second run\n",
    "* 370 seconds at 100k batch size\n",
    "* 370 seconds at 50k batch \n",
    "* 370ish seconds at 10k batch\n",
    "\n",
    "Concerned the first-run test absorbs a lot of the processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1de66-526e-47f7-b084-7590640d92bc",
   "metadata": {},
   "source": [
    "For 567,484 probabilities using the `pg-bulg-ingest` methodology.\n",
    "\n",
    "* xx seconds at 500k batch size\n",
    "* xx seconds at 250k batch size\n",
    "* xx seconds at 100k batch size\n",
    "* xx seconds at 50k batch \n",
    "* xx seconds at 10k batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6109134f-3240-4529-b1e4-c8b70bb186ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ew_deduped.dataframe.head(10).to_records(index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "581fd20b-a57e-4876-a8f5-effce230d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'\\x03\\xfb\\xaf\\xea\\xb1\\xe3O\\xcbY\\x11p\\\\2\\x83\\x19\\xf8\\xb4\\xe1L\\x1d', b']\\x92\\x90V\\xda\\xc2\\xe0\\xbe\\t\\xb385\\x9bx%f{\\xdc\\x07O', 1, b'\\x1a\\x86\\x83\\xbf\\xe8I\\x8f\\x14\\xe7\\xe8i\\xe0\\xa5D\\x16w8\\x05,R')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd3f546-c518-487b-bb05-b66bf7269a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmf.data import Dedupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1d6660-425f-44ee-86e5-c5d25cad285f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dedupes.__table__.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71c30c31-6778-4d9d-a591-92dbd67522b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ew_deduped._to_batch(\n",
    "    dataframe=ew_deduped._prep_to_cmf(ew_deduped.dataframe)[[\"sha1\", \"left\", \"right\"]], \n",
    "    table=Dedupes.__table__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfc7893a-c678-45ef-8035-645dd9773b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha1</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\x1a\\x86\\x83\\xbf\\xe8I\\x8f\\x14\\xe7\\xe8i\\xe0\\x...</td>\n",
       "      <td>b'\\x03\\xfb\\xaf\\xea\\xb1\\xe3O\\xcbY\\x11p\\\\2\\x83\\x...</td>\n",
       "      <td>b']\\x92\\x90V\\xda\\xc2\\xe0\\xbe\\t\\xb385\\x9bx%f{\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\x08\\xdd\\x1e\\x85r\\xa6\\x14\"\\x1b&gt;r3\\x85E\\xd4|\\...</td>\n",
       "      <td>b'v\\xc6\\xa7\\tM\\xbay\\x96\\x19\\x03e\\xe8\\xec\\xb6r\\...</td>\n",
       "      <td>b'\\xa5\\xceT\\x06\\xad\\x8eg\\xaa\\x81\\xc6\\n\\x9bs\\x9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\xe8{J\\xc0[\\xfa\\xe7Y\\xd4M\\t\\xf1V\\x9a\\x07\\x1b...</td>\n",
       "      <td>b'#\\t\\x8a|1\\x01\\xfb|u\\xb3\\xcdf\\xf7\\xa3\\x97\\xbf...</td>\n",
       "      <td>b'\\xad&gt;H\\x14\\x83\\x15&amp;\\xe5\\xfcn\\xb3\\xef\\x8a\\xa0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sha1  \\\n",
       "0  b'\\x1a\\x86\\x83\\xbf\\xe8I\\x8f\\x14\\xe7\\xe8i\\xe0\\x...   \n",
       "1  b'\\x08\\xdd\\x1e\\x85r\\xa6\\x14\"\\x1b>r3\\x85E\\xd4|\\...   \n",
       "2  b'\\xe8{J\\xc0[\\xfa\\xe7Y\\xd4M\\t\\xf1V\\x9a\\x07\\x1b...   \n",
       "\n",
       "                                                left  \\\n",
       "0  b'\\x03\\xfb\\xaf\\xea\\xb1\\xe3O\\xcbY\\x11p\\\\2\\x83\\x...   \n",
       "1  b'v\\xc6\\xa7\\tM\\xbay\\x96\\x19\\x03e\\xe8\\xec\\xb6r\\...   \n",
       "2  b'#\\t\\x8a|1\\x01\\xfb|u\\xb3\\xcdf\\xf7\\xa3\\x97\\xbf...   \n",
       "\n",
       "                                               right  \n",
       "0  b']\\x92\\x90V\\xda\\xc2\\xe0\\xbe\\t\\xb385\\x9bx%f{\\x...  \n",
       "1  b'\\xa5\\xceT\\x06\\xad\\x8eg\\xaa\\x81\\xc6\\n\\x9bs\\x9...  \n",
       "2  b'\\xad>H\\x14\\x83\\x15&\\xe5\\xfcn\\xb3\\xef\\x8a\\xa0...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ew_deduped._prep_to_cmf(ew_deduped.dataframe)[[\"sha1\", \"left\", \"right\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc84284-0750-4f9a-9d7d-ea795c04d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in batch(None):\n",
    "    i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f462c5a-8469-4403-9464-ee2275f9b8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-12 11:32:18,530: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Registering model\n",
      "[2024-03-12 11:32:18,570: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Writing deduplication data with batch size 250000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'upper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m ew_deduped\u001b[38;5;241m.\u001b[39m_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250_000\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sqa_profiled():\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mew_deduped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_cmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/company-matching/cmf/data/results.py:161\u001b[0m, in \u001b[0;36mResultsBaseDataclass.to_cmf\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m         logic_logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Writing deduplication data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deduper_to_cmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Linker\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Write model\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     logic_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Registering model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/company-matching/cmf/data/results.py:328\u001b[0m, in \u001b[0;36mProbabilityResults._deduper_to_cmf\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deduper_to_cmf\u001b[39m(\u001b[38;5;28mself\u001b[39m, engine: Engine \u001b[38;5;241m=\u001b[39m ENGINE) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Writes the results of a deduper to the CMF database.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    * Turns data into a left, right, sha1, probability dataframe\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m        CMFDBDataError if current model wasn't inserted correctly\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     probabilities_to_add \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_to_cmf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     logic_logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Processed %s link probabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mlen\u001b[39m(probabilities_to_add),\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# Validate tables exist\u001b[39;00m\n",
      "File \u001b[0;32m~/company-matching/cmf/data/results.py:300\u001b[0m, in \u001b[0;36mProbabilityResults._prep_to_cmf\u001b[0;34m(self, df, engine)\u001b[0m\n\u001b[1;32m    298\u001b[0m pre_prep_df\u001b[38;5;241m.\u001b[39msha1 \u001b[38;5;241m=\u001b[39m pre_prep_df\u001b[38;5;241m.\u001b[39msha1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m    299\u001b[0m bin_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 300\u001b[0m pre_prep_df[bin_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mpre_prep_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbin_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pre_prep_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/frame.py:10441\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/frame.py:10439\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/company-matching/cmf/data/results.py:301\u001b[0m, in \u001b[0;36mProbabilityResults._prep_to_cmf.<locals>.<lambda>\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    298\u001b[0m pre_prep_df\u001b[38;5;241m.\u001b[39msha1 \u001b[38;5;241m=\u001b[39m pre_prep_df\u001b[38;5;241m.\u001b[39msha1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m    299\u001b[0m bin_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    300\u001b[0m pre_prep_df[bin_cols] \u001b[38;5;241m=\u001b[39m pre_prep_df[bin_cols]\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m()\n\u001b[1;32m    302\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pre_prep_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'upper'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ew_deduped._batch_size = 250_000\n",
    "\n",
    "with sqa_profiled():\n",
    "    ew_deduped.to_cmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7639271-0294-4cce-9f69-ad12acbb8765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_id</th>\n",
       "      <th>right_id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI&lt; \\xc7^+l...</td>\n",
       "      <td>b'v\\xa9=\\x14\\xc2\\xc2~\\xa7\\xbe\\xb9\\xa2\\xe6\\xe2M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'?@\\xf4\\xa9\\xbeBQ\\xa8\\x7fn\\xcbT\\xac\\xedL\\x05\\...</td>\n",
       "      <td>b'\\xf3\\xce\\xa4\\xe4H\\r\\xcf\\xaf\\x11IfH\\xf9\\xc4\\x...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\xfe^[\\xea\\xecLt\\x08O\\x0b\\x11.\\xdf*\\xcb\\x89K...</td>\n",
       "      <td>b'-I\\xf4:\\xb6\\xeb\\xb4\\xd9\\xbb\\xe0\\xc4\\xb7V4\\xc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             left_id  \\\n",
       "0  b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI< \\xc7^+l...   \n",
       "1  b'?@\\xf4\\xa9\\xbeBQ\\xa8\\x7fn\\xcbT\\xac\\xedL\\x05\\...   \n",
       "2  b'\\xfe^[\\xea\\xecLt\\x08O\\x0b\\x11.\\xdf*\\xcb\\x89K...   \n",
       "\n",
       "                                            right_id  probability  \n",
       "0  b'v\\xa9=\\x14\\xc2\\xc2~\\xa7\\xbe\\xb9\\xa2\\xe6\\xe2M...            1  \n",
       "1  b'\\xf3\\xce\\xa4\\xe4H\\r\\xcf\\xaf\\x11IfH\\xf9\\xc4\\x...            1  \n",
       "2  b'-I\\xf4:\\xb6\\xeb\\xb4\\xd9\\xbb\\xe0\\xc4\\xb7V4\\xc...            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90276899 entries, 0 to 90276898\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Dtype          \n",
      "---  ------       -----          \n",
      " 0   left_id      binary[pyarrow]\n",
      " 1   right_id     binary[pyarrow]\n",
      " 2   probability  int32[pyarrow] \n",
      "dtypes: binary[pyarrow](2), int32[pyarrow](1)\n",
      "memory usage: 4.4 GB\n"
     ]
    }
   ],
   "source": [
    "with s3.read(path=\"hmrc_exporters_probabilities.parquet\") as f:\n",
    "    exp_deduped = pd.read_parquet(f, dtype_backend=\"pyarrow\")\n",
    "\n",
    "exp_deduped.left_id = exp_deduped.left_id.astype(\"binary[pyarrow]\")\n",
    "exp_deduped.right_id = exp_deduped.right_id.astype(\"binary[pyarrow]\")\n",
    "\n",
    "exp_deduped.head(3)\n",
    "exp_deduped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939e89e8-a2e8-4b29-a52a-96964885d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = (\n",
    "    exp_deduped\n",
    "    .query(\"probability >= 1\")\n",
    "    .filter([\"left_id\", \"right_id\"])\n",
    "    .itertuples(index=False, name=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c9992e-b544-4693-b7c0-bab103efc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = rx.PyGraph()\n",
    "added = {}\n",
    "\n",
    "for edge in all_edges:\n",
    "    edge_idx = []\n",
    "    for sha1 in edge:\n",
    "        sha1_idx = added.get(sha1)\n",
    "        if sha1_idx is None:\n",
    "            sha1_idx = G.add_node(sha1)\n",
    "            added[sha1] = sha1_idx\n",
    "        edge_idx.append(sha1_idx)\n",
    "    edge_idx.append(None)\n",
    "    _ = G.add_edge(*edge_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfadc38c-a5a9-4451-8bb8-d13a1121b82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d92dd7a-d25d-4daa-bcfd-8442ca322486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI< \\xc7^+l\\xdf'\n"
     ]
    }
   ],
   "source": [
    "for edge in all_edges:\n",
    "    print(edge)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85cd00ab-ce8e-4afe-a667-d8e70aa43fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI< \\xc7^+l\\xdf', b'v\\xa9=\\x14\\xc2\\xc2~\\xa7\\xbe\\xb9\\xa2\\xe6\\xe2M\\xca\\x9d\\xf6(\\x0b1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    exp_deduped\n",
    "    .head(100_000)\n",
    "    .query(\"probability >= 1\")\n",
    "    .filter([\"left_id\", \"right_id\"])\n",
    "    .to_records()\n",
    ")[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_matching",
   "language": "python",
   "name": "company_matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
