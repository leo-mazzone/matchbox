{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123cf1dc-6310-4183-b12a-0879b927047b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://s3-eu-west-2.amazonaws.com/mirrors.notebook.uktrade.io/pypi/\n",
      "Collecting dwutils@ git+ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest\n",
      "  Cloning ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git (to revision latest) to /tmp/pip-install-e41jcl0i/dwutils_f4b1526497354be2bfcac10880e133e4\n",
      "  Running command git clone --filter=blob:none --quiet 'ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git' /tmp/pip-install-e41jcl0i/dwutils_f4b1526497354be2bfcac10880e133e4\n",
      "  Resolved ssh://****@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git to commit 20144945565fe9e71c91311da3401156e12095ed\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gitpython in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.1.42)\n",
      "Requirement already satisfied: mlflow-skinny==2.10.* in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.10.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.12.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.0)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.9.7)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (15.0.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.0.20)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.34.58)\n",
      "Requirement already satisfied: tomli in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.62.3)\n",
      "Requirement already satisfied: git-lfs-http-mirror in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.0.7)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.8.1)\n",
      "Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.0)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (6.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.25.3)\n",
      "Requirement already satisfied: pytz<2024 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (23.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (7.0.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from gitpython->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.0.11)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.58 in /opt/conda/lib/python3.9/site-packages (from boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.34.58)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.10.0)\n",
      "Requirement already satisfied: httpx>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.24.1)\n",
      "Requirement already satisfied: hypercorn>=0.14.3 in /opt/conda/lib/python3.9/site-packages (from git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.14.4)\n",
      "Requirement already satisfied: quart>=0.19.4 in /opt/conda/lib/python3.9/site-packages (from git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.19.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.12.25)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.9/site-packages (from pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.35.0,>=1.34.58->boto3->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.26.18)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (5.0.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.17.3)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.3.0)\n",
      "Requirement already satisfied: h11 in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (0.14.0)\n",
      "Requirement already satisfied: h2>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.1.0)\n",
      "Requirement already satisfied: priority in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.16.0)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (23.2.1)\n",
      "Requirement already satisfied: blinker>=1.6 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.7.0)\n",
      "Requirement already satisfied: flask>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.2)\n",
      "Requirement already satisfied: itsdangerous in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.1.3)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (2.1.3)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from quart>=0.19.4->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.10.*->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/conda/lib/python3.9/site-packages (from h2>=3.1.0->hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/conda/lib/python3.9/site-packages (from h2>=3.1.0->hypercorn>=0.14.3->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.0.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (4.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.9/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx>=0.23.1->git-lfs-http-mirror->dwutils@ git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dwutils@git+ssh://git@gitlab.data.trade.gov.uk/ddatdatascienceteam/data-workspace-utilities.git@latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c76d233-7a6a-4d82-abd0-3ba75343de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3912d8f-6c0c-4767-bd6d-1af8339b9605",
   "metadata": {},
   "source": [
    "# Massive connected components\n",
    "\n",
    "Connected components crashes on 90m probabilities. We need to be able to handle that and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05f280b4-811c-48b9-8316-87c5414b41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmf\n",
    "from cmf import clean\n",
    "from cmf.clean import steps\n",
    "from cmf.data.utils import sqa_profiled\n",
    "from cmf.dedupers import NaiveDeduper\n",
    "from cmf.helpers import cleaner, cleaners, selector\n",
    "from cmf.data.results import ClusterResults, ProbabilityResults\n",
    "\n",
    "import logging\n",
    "\n",
    "from dwutils import s3\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pyarrow as pa\n",
    "import rustworkx as rx\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "def create_cmf_pipelines_logger() -> logging.Logger:\n",
    "    pipeline_logger = logging.getLogger(\"cmf_pipelines\")\n",
    "    logic_logger = logging.getLogger(\"cmf_logic\")\n",
    "\n",
    "    pipeline_logger.setLevel(logging.INFO)\n",
    "    logic_logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s: %(levelname)s] %(name)s %(module)s: %(message)s\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    pipeline_logger.addHandler(handler)\n",
    "    logic_logger.addHandler(handler)\n",
    "\n",
    "    return pipeline_logger\n",
    "\n",
    "\n",
    "logger = create_cmf_pipelines_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d431277-3fee-46b7-bdbf-5944e9a750c4",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09e50c7d-107d-43e2-88ec-c184f2d5a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NAME = \"naive_hmrc_exports_v1\"\n",
    "_SOURCE = \"hmrc.trade__exporters\"\n",
    "\n",
    "\n",
    "def _query(limit: Optional[int] = None) -> DataFrame:\n",
    "    \"\"\"Select data.\"\"\"\n",
    "\n",
    "    exp_selector = selector(\n",
    "        table=_SOURCE,\n",
    "        fields=[\"company_name\", \"postcode\"],\n",
    "    )\n",
    "\n",
    "    exp_raw = cmf.query(selector=exp_selector, return_type=\"pandas\", limit=limit)\n",
    "\n",
    "    logger.info(\n",
    "        \"Data retrieved successfully with %s unique datapoints\",\n",
    "        exp_raw.data_sha1.nunique(),\n",
    "    )\n",
    "\n",
    "    return exp_raw\n",
    "\n",
    "\n",
    "def _process(raw: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean data.\"\"\"\n",
    "\n",
    "    clean_exp = cleaners(\n",
    "        cleaner(clean.company_name, {\"column\": \"hmrc_trade__exporters_company_name\"}),\n",
    "        cleaner(clean.postcode, {\"column\": \"hmrc_trade__exporters_postcode\"}),\n",
    "    )\n",
    "\n",
    "    exp_clean = cmf.process(raw, clean_exp)\n",
    "\n",
    "    logger.info(\"Data cleaned successfully\")\n",
    "\n",
    "    return exp_clean\n",
    "\n",
    "\n",
    "def _deduplicate(clean: DataFrame) -> ProbabilityResults:\n",
    "    \"\"\"Deduplicate data.\"\"\"\n",
    "\n",
    "    exp_naive_deduper = cmf.make_deduper(\n",
    "        dedupe_run_name=_NAME,\n",
    "        description=\"Basic cleaning of name and postcode.\",\n",
    "        deduper=NaiveDeduper,\n",
    "        deduper_settings={\n",
    "            \"id\": \"data_sha1\",\n",
    "            \"unique_fields\": [\n",
    "                \"hmrc_trade__exporters_company_name\",\n",
    "                \"hmrc_trade__exporters_postcode\",\n",
    "            ],\n",
    "        },\n",
    "        data=clean,\n",
    "        data_source=_SOURCE,\n",
    "    )\n",
    "\n",
    "    exp_deduped = exp_naive_deduper()\n",
    "\n",
    "    logger.info(\n",
    "        \"Data deduplicated successfully. %s probabilities generated\",\n",
    "        exp_deduped.dataframe.shape[0],\n",
    "    )\n",
    "\n",
    "    return exp_deduped\n",
    "\n",
    "\n",
    "def _cluster(deduped: ProbabilityResults, clean: DataFrame) -> ClusterResults:\n",
    "    \"\"\"Resolve probabilities to clusters.\"\"\"\n",
    "    exp_clusters = cmf.to_clusters(clean, results=deduped, key=\"data_sha1\", threshold=1)\n",
    "\n",
    "    logger.info(\n",
    "        \"Clusters resolved successfully. %s clusters generated\",\n",
    "        exp_clusters.dataframe.parent.nunique(),\n",
    "    )\n",
    "\n",
    "    return exp_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bea25be-9933-4310-89b5-486d4a8e820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-11 13:03:36,385: INFO] cmf_pipelines 2290665410: Data retrieved successfully with 300000 unique datapoints\n",
      "[2024-03-11 13:03:40,044: INFO] cmf_pipelines 2290665410: Data cleaned successfully\n",
      "[2024-03-11 13:03:41,787: INFO] cmf_pipelines 2290665410: Data deduplicated successfully. 567484 probabilities generated\n",
      "[2024-03-11 13:03:44,299: INFO] cmf_pipelines 2290665410: Clusters resolved successfully. 109616 clusters generated\n"
     ]
    }
   ],
   "source": [
    "ew_raw = _query(limit=300_000)\n",
    "ew_clean = _process(raw=ew_raw)\n",
    "ew_deduped = _deduplicate(clean=ew_clean)\n",
    "ew_clusters = _cluster(deduped=ew_deduped, clean=ew_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d7549-7643-4bce-8aab-91954a2e67cf",
   "metadata": {},
   "source": [
    "## Playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5a194b2-0168-4f4a-849d-08e552b9d311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3793000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count\n",
       "0  3793000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dwutils import db\n",
    "\n",
    "db.query(f\"select count(*) from {_SOURCE};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af98ab-44ea-40f9-8485-640f8b684a0f",
   "metadata": {},
   "source": [
    "For 567,484 probabilities using the `WriteOnlyMapped` methodology.\n",
    "\n",
    "* 394 seconds at 500k batch size\n",
    "* 585 seconds at 250k batch size\n",
    "    * `execute` and `_emit_insert_statements` are like 400s of that\n",
    "    * 390 on second run\n",
    "* 370 seconds at 100k batch size\n",
    "* 370 seconds at 50k batch \n",
    "* 370ish seconds at 10k batch\n",
    "\n",
    "Concerned the first-run test absorbs a lot of the processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6109134f-3240-4529-b1e4-c8b70bb186ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ew_deduped.dataframe.head(10).to_records(index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "581fd20b-a57e-4876-a8f5-effce230d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'\\x03\\xfb\\xaf\\xea\\xb1\\xe3O\\xcbY\\x11p\\\\2\\x83\\x19\\xf8\\xb4\\xe1L\\x1d', b']\\x92\\x90V\\xda\\xc2\\xe0\\xbe\\t\\xb385\\x9bx%f{\\xdc\\x07O', 1, b'\\x1a\\x86\\x83\\xbf\\xe8I\\x8f\\x14\\xe7\\xe8i\\xe0\\xa5D\\x16w8\\x05,R')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcd3f546-c518-487b-bb05-b66bf7269a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmf.data import Dedupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea1d6660-425f-44ee-86e5-c5d25cad285f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('cmf__ddupes', MetaData(), Column('left', LargeBinary(), ForeignKey('cmf__source_data.sha1'), table=<cmf__ddupes>, nullable=False), Column('right', LargeBinary(), ForeignKey('cmf__source_data.sha1'), table=<cmf__ddupes>, nullable=False), Column('sha1', LargeBinary(), table=<cmf__ddupes>, primary_key=True, nullable=False), schema='_team_cmf')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dedupes.__table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71c30c31-6778-4d9d-a591-92dbd67522b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ew_deduped._to_batch(\n",
    "    dataframe=ew_deduped._prep_to_cmf(ew_deduped.dataframe)[[\"sha1\", \"left\", \"right\"]], \n",
    "    table=Dedupes.__table__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfc7893a-c678-45ef-8035-645dd9773b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha1</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\x1a\\x86\\x83\\xbf\\xe8I\\x8f\\x14\\xe7\\xe8i\\xe0\\x...</td>\n",
       "      <td>b'\\x03\\xfb\\xaf\\xea\\xb1\\xe3O\\xcbY\\x11p\\\\2\\x83\\x...</td>\n",
       "      <td>b']\\x92\\x90V\\xda\\xc2\\xe0\\xbe\\t\\xb385\\x9bx%f{\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\x08\\xdd\\x1e\\x85r\\xa6\\x14\"\\x1b&gt;r3\\x85E\\xd4|\\...</td>\n",
       "      <td>b'v\\xc6\\xa7\\tM\\xbay\\x96\\x19\\x03e\\xe8\\xec\\xb6r\\...</td>\n",
       "      <td>b'\\xa5\\xceT\\x06\\xad\\x8eg\\xaa\\x81\\xc6\\n\\x9bs\\x9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\xe8{J\\xc0[\\xfa\\xe7Y\\xd4M\\t\\xf1V\\x9a\\x07\\x1b...</td>\n",
       "      <td>b'#\\t\\x8a|1\\x01\\xfb|u\\xb3\\xcdf\\xf7\\xa3\\x97\\xbf...</td>\n",
       "      <td>b'\\xad&gt;H\\x14\\x83\\x15&amp;\\xe5\\xfcn\\xb3\\xef\\x8a\\xa0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sha1  \\\n",
       "0  b'\\x1a\\x86\\x83\\xbf\\xe8I\\x8f\\x14\\xe7\\xe8i\\xe0\\x...   \n",
       "1  b'\\x08\\xdd\\x1e\\x85r\\xa6\\x14\"\\x1b>r3\\x85E\\xd4|\\...   \n",
       "2  b'\\xe8{J\\xc0[\\xfa\\xe7Y\\xd4M\\t\\xf1V\\x9a\\x07\\x1b...   \n",
       "\n",
       "                                                left  \\\n",
       "0  b'\\x03\\xfb\\xaf\\xea\\xb1\\xe3O\\xcbY\\x11p\\\\2\\x83\\x...   \n",
       "1  b'v\\xc6\\xa7\\tM\\xbay\\x96\\x19\\x03e\\xe8\\xec\\xb6r\\...   \n",
       "2  b'#\\t\\x8a|1\\x01\\xfb|u\\xb3\\xcdf\\xf7\\xa3\\x97\\xbf...   \n",
       "\n",
       "                                               right  \n",
       "0  b']\\x92\\x90V\\xda\\xc2\\xe0\\xbe\\t\\xb385\\x9bx%f{\\x...  \n",
       "1  b'\\xa5\\xceT\\x06\\xad\\x8eg\\xaa\\x81\\xc6\\n\\x9bs\\x9...  \n",
       "2  b'\\xad>H\\x14\\x83\\x15&\\xe5\\xfcn\\xb3\\xef\\x8a\\xa0...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ew_deduped._prep_to_cmf(ew_deduped.dataframe)[[\"sha1\", \"left\", \"right\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc84284-0750-4f9a-9d7d-ea795c04d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in batch(None):\n",
    "    i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f462c5a-8469-4403-9464-ee2275f9b8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:27:26,768: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Registering model\n",
      "[2024-03-11 17:27:26,768: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Registering model\n",
      "[2024-03-11 17:27:26,768: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Registering model\n",
      "[2024-03-11 17:27:26,780: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Writing deduplication data with batch size 250000\n",
      "[2024-03-11 17:27:26,780: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Writing deduplication data with batch size 250000\n",
      "[2024-03-11 17:27:26,780: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Writing deduplication data with batch size 250000\n",
      "[2024-03-11 17:27:48,657: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Processed 567484 link probabilities\n",
      "[2024-03-11 17:27:48,657: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Processed 567484 link probabilities\n",
      "[2024-03-11 17:27:48,657: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Processed 567484 link probabilities\n",
      "[2024-03-11 17:27:49,152: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Removed old deduplication probabilities\n",
      "[2024-03-11 17:27:49,152: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Removed old deduplication probabilities\n",
      "[2024-03-11 17:27:49,152: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Removed old deduplication probabilities\n",
      "[2024-03-11 17:27:49,155: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Inserting 567484 deduplication objects\n",
      "[2024-03-11 17:27:49,155: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Inserting 567484 deduplication objects\n",
      "[2024-03-11 17:27:49,155: INFO] cmf_logic results: [naive_hmrc_exports_v1, ProbabilityResults] Inserting 567484 deduplication objects\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.InsufficientPrivilege) permission denied for database public_datasets_1\n\n[SQL: \n            CREATE SCHEMA IF NOT EXISTS \"_team_cmf\"\n        ]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInsufficientPrivilege\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 922\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInsufficientPrivilege\u001b[0m: permission denied for database public_datasets_1\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m ew_deduped\u001b[38;5;241m.\u001b[39m_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250_000\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sqa_profiled():\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mew_deduped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_cmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/company-matching/cmf/data/results.py:161\u001b[0m, in \u001b[0;36mResultsBaseDataclass.to_cmf\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m         logic_logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Writing deduplication data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deduper_to_cmf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Linker\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Write model\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     logic_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Registering model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/company-matching/cmf/data/results.py:369\u001b[0m, in \u001b[0;36mProbabilityResults._deduper_to_cmf\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Upsert dedupe nodes\u001b[39;00m\n\u001b[1;32m    364\u001b[0m fn_dedupe_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_batch(\n\u001b[1;32m    365\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mprobabilities_to_add[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m]], \n\u001b[1;32m    366\u001b[0m     table\u001b[38;5;241m=\u001b[39mDedupes\u001b[38;5;241m.\u001b[39m__table__\n\u001b[1;32m    367\u001b[0m )\n\u001b[0;32m--> 369\u001b[0m \u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDedupes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_dedupe_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupsert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUpsert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIF_PRIMARY_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# Insert dedupe probabilities\u001b[39;00m\n\u001b[1;32m    377\u001b[0m fn_dedupe_probs_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_batch(\n\u001b[1;32m    378\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    379\u001b[0m         probabilities_to_add\u001b[38;5;241m.\u001b[39massign(model\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39msha1)[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     table\u001b[38;5;241m=\u001b[39mDDupeProbabilities\u001b[38;5;241m.\u001b[39m__table__,\n\u001b[1;32m    384\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/pg_bulk_ingest.py:277\u001b[0m, in \u001b[0;36mingest\u001b[0;34m(conn, metadata, batches, high_watermark, visibility, upsert, delete, get_pg_force_execute, on_before_visible, logger, max_rows_per_table_buffer)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_table \u001b[38;5;129;01min\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mtables\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    276\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating target table \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m if it does\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt already exist\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_table)\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind_identifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;43m        CREATE SCHEMA IF NOT EXISTS \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     initial_table_metadata \u001b[38;5;241m=\u001b[39m sa\u001b[38;5;241m.\u001b[39mMetaData()\n\u001b[1;32m    281\u001b[0m     initial_table \u001b[38;5;241m=\u001b[39m sa\u001b[38;5;241m.\u001b[39mTable(\n\u001b[1;32m    282\u001b[0m         target_table\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    283\u001b[0m         initial_table_metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         schema\u001b[38;5;241m=\u001b[39mtarget_table\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m    289\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:517\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1639\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1627\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1629\u001b[0m )\n\u001b[1;32m   1631\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1632\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1633\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1637\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1638\u001b[0m )\n\u001b[0;32m-> 1639\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1653\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1654\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         ret,\n\u001b[1;32m   1659\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1848\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1844\u001b[0m         dialect,\n\u001b[1;32m   1845\u001b[0m         context,\n\u001b[1;32m   1846\u001b[0m     )\n\u001b[1;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1988\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1985\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2344\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2343\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1975\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1976\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1980\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1981\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/company_matching/lib/python3.9/site-packages/sqlalchemy/engine/default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 922\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.InsufficientPrivilege) permission denied for database public_datasets_1\n\n[SQL: \n            CREATE SCHEMA IF NOT EXISTS \"_team_cmf\"\n        ]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ew_deduped._batch_size = 250_000\n",
    "\n",
    "with sqa_profiled():\n",
    "    ew_deduped.to_cmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3980ad-a595-41ca-9f50-0aba1e37326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CMF schema\n",
    "if not inspect(conn).has_schema(os.getenv(\"SCHEMA\")):\n",
    "    conn.execute(CreateSchema(os.getenv(\"SCHEMA\")))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7639271-0294-4cce-9f69-ad12acbb8765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_id</th>\n",
       "      <th>right_id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI&lt; \\xc7^+l...</td>\n",
       "      <td>b'v\\xa9=\\x14\\xc2\\xc2~\\xa7\\xbe\\xb9\\xa2\\xe6\\xe2M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'?@\\xf4\\xa9\\xbeBQ\\xa8\\x7fn\\xcbT\\xac\\xedL\\x05\\...</td>\n",
       "      <td>b'\\xf3\\xce\\xa4\\xe4H\\r\\xcf\\xaf\\x11IfH\\xf9\\xc4\\x...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\xfe^[\\xea\\xecLt\\x08O\\x0b\\x11.\\xdf*\\xcb\\x89K...</td>\n",
       "      <td>b'-I\\xf4:\\xb6\\xeb\\xb4\\xd9\\xbb\\xe0\\xc4\\xb7V4\\xc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             left_id  \\\n",
       "0  b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI< \\xc7^+l...   \n",
       "1  b'?@\\xf4\\xa9\\xbeBQ\\xa8\\x7fn\\xcbT\\xac\\xedL\\x05\\...   \n",
       "2  b'\\xfe^[\\xea\\xecLt\\x08O\\x0b\\x11.\\xdf*\\xcb\\x89K...   \n",
       "\n",
       "                                            right_id  probability  \n",
       "0  b'v\\xa9=\\x14\\xc2\\xc2~\\xa7\\xbe\\xb9\\xa2\\xe6\\xe2M...            1  \n",
       "1  b'\\xf3\\xce\\xa4\\xe4H\\r\\xcf\\xaf\\x11IfH\\xf9\\xc4\\x...            1  \n",
       "2  b'-I\\xf4:\\xb6\\xeb\\xb4\\xd9\\xbb\\xe0\\xc4\\xb7V4\\xc...            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90276899 entries, 0 to 90276898\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Dtype          \n",
      "---  ------       -----          \n",
      " 0   left_id      binary[pyarrow]\n",
      " 1   right_id     binary[pyarrow]\n",
      " 2   probability  int32[pyarrow] \n",
      "dtypes: binary[pyarrow](2), int32[pyarrow](1)\n",
      "memory usage: 4.4 GB\n"
     ]
    }
   ],
   "source": [
    "with s3.read(path=\"hmrc_exporters_probabilities.parquet\") as f:\n",
    "    exp_deduped = pd.read_parquet(f, dtype_backend=\"pyarrow\")\n",
    "\n",
    "exp_deduped.left_id = exp_deduped.left_id.astype(\"binary[pyarrow]\")\n",
    "exp_deduped.right_id = exp_deduped.right_id.astype(\"binary[pyarrow]\")\n",
    "\n",
    "exp_deduped.head(3)\n",
    "exp_deduped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939e89e8-a2e8-4b29-a52a-96964885d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = (\n",
    "    exp_deduped\n",
    "    .query(\"probability >= 1\")\n",
    "    .filter([\"left_id\", \"right_id\"])\n",
    "    .itertuples(index=False, name=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c9992e-b544-4693-b7c0-bab103efc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = rx.PyGraph()\n",
    "added = {}\n",
    "\n",
    "for edge in all_edges:\n",
    "    edge_idx = []\n",
    "    for sha1 in edge:\n",
    "        sha1_idx = added.get(sha1)\n",
    "        if sha1_idx is None:\n",
    "            sha1_idx = G.add_node(sha1)\n",
    "            added[sha1] = sha1_idx\n",
    "        edge_idx.append(sha1_idx)\n",
    "    edge_idx.append(None)\n",
    "    _ = G.add_edge(*edge_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfadc38c-a5a9-4451-8bb8-d13a1121b82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d92dd7a-d25d-4daa-bcfd-8442ca322486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI< \\xc7^+l\\xdf'\n"
     ]
    }
   ],
   "source": [
    "for edge in all_edges:\n",
    "    print(edge)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85cd00ab-ce8e-4afe-a667-d8e70aa43fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, b'\\\\s31\\x86\\xbb\\xd0s\\xa2\\x92\\x8a\\xadI< \\xc7^+l\\xdf', b'v\\xa9=\\x14\\xc2\\xc2~\\xa7\\xbe\\xb9\\xa2\\xe6\\xe2M\\xca\\x9d\\xf6(\\x0b1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    exp_deduped\n",
    "    .head(100_000)\n",
    "    .query(\"probability >= 1\")\n",
    "    .filter([\"left_id\", \"right_id\"])\n",
    "    .to_records()\n",
    ")[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_matching",
   "language": "python",
   "name": "company_matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
