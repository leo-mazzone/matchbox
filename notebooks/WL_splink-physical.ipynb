{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41289fef-1d16-4d33-8ee4-a6e120f06cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b6cebf-85bb-49c9-9120-8f5b13cfbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pyarrow.dataset as ds\n",
    "from pgpq import ArrowToPostgresBinaryEncoder\n",
    "import psycopg\n",
    "from tqdm import tqdm\n",
    "import duckdb\n",
    "\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "\n",
    "from src.data import utils as du\n",
    "import src.locations as loc\n",
    "from src.config import settings\n",
    "\n",
    "CLUSTER_PATH = Path(loc.DATA_SUBDIR['processed']) / 'company-matching__full' / 'clusters.parquet' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfbcb7-f88b-4412-949c-3f59ddf13685",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using Splink with physical duckdb\n",
    "\n",
    "Gonna try and run it off the file system. Raw db about 1GB pre-Splink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e42069-7719-467d-8dd2-5a66cac6be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = du.get_duckdb_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af87a859-1957-42b0-a49b-97a148d66ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = []\n",
    "table_alias = []\n",
    "\n",
    "for i in con.query(\"select * from table_alias_lookup;\").fetchall():\n",
    "    table_alias.append(i[0])\n",
    "    table_name.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2def9a4f-16d5-49eb-80b6-6c3d3482f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = DuckDBLinker(\n",
    "    table_name,\n",
    "    settings_dict=settings,\n",
    "    connection=con,\n",
    "    input_table_aliases=table_alias,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515f37c-9cca-4a1c-988f-95b539cb182b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5107e63b-09a3-492a-b1e1-e6a3be30abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  3.24e-06.\n",
      "This means that amongst all possible pairwise record comparisons, one in 309,025.51 are expected to match.  With 40,009,433,095,801 total possible comparisons, we expect a total of around 129,469,675.71 matching pairs\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_probability_two_random_records_match(\n",
    "    \"l.name_unusual_tokens = r.name_unusual_tokens\",\n",
    "    recall=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c00d60a-7a09-41b2-9957-5faf36053675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n",
      "u probability not trained for comp_num_clean - Exact match (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - comp_num_clean (some u values are not trained, no m values are trained).\n",
      "    - name_unusual_tokens (no m values are trained).\n",
      "    - postcode (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf50a59-457f-4219-8c10-2671779a3944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "---- Estimating m probabilities using from column comp_num_clean -----\n",
      "m probability not trained for comp_num_clean - Jaro_winkler_similarity >= 0.75 (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for comp_num_clean - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - comp_num_clean (some u values are not trained, some m values are not trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "\n",
      "    l.name_unusual_tokens = r.name_unusual_tokens\n",
      "    and l.postcode_area = r.postcode_area\n",
      "\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - comp_num_clean\n",
      "    - postcode\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - name_unusual_tokens\n",
      "\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison postcode not observed in dataset, unable to train m value\n",
      "Iteration 1: Largest change in params was 0.71 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison postcode not observed in dataset, unable to train m value\n",
      "Iteration 2: Largest change in params was -0.0579 in the m_probability of comp_num_clean, level `Exact match`\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison postcode not observed in dataset, unable to train m value\n",
      "Iteration 3: Largest change in params was 0.0073 in the m_probability of comp_num_clean, level `All other comparisons`\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison postcode not observed in dataset, unable to train m value\n",
      "Iteration 4: Largest change in params was 7.84e-05 in the m_probability of comp_num_clean, level `All other comparisons`\n",
      "\n",
      "EM converged after 4 iterations\n",
      "m probability not trained for postcode - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - comp_num_clean (some u values are not trained).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<EMTrainingSession, blocking on \n",
       "    l.name_unusual_tokens = r.name_unusual_tokens\n",
       "    and l.postcode_area = r.postcode_area\n",
       ", deactivating comparisons name_unusual_tokens>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.estimate_m_from_label_column(\"comp_num_clean\")\n",
    "m_by_name_and_postcode_area = \"\"\"\n",
    "    l.name_unusual_tokens = r.name_unusual_tokens\n",
    "    and l.postcode_area = r.postcode_area\n",
    "\"\"\"\n",
    "linker.estimate_parameters_using_expectation_maximisation(\n",
    "    m_by_name_and_postcode_area\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c4bc3-fd4e-4b86-ac4d-212c0f0c3a4c",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5712b44-6919-4420-9b93-14468f8e0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'comp_num_clean':\n",
      "    u values not fully trained\n"
     ]
    }
   ],
   "source": [
    "predictions = linker.predict(threshold_match_probability=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b4d9b-b283-47d8-a58b-03b68bb04a12",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0845d55e-7f69-4794-ae6c-2a68facc55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_table = con.query(\"\"\"\n",
    "    select table_name\n",
    "    from information_schema.tables\n",
    "    where table_name like '%predict%';\n",
    "\"\"\").fetchone()[0]\n",
    "predictions = linker.register_table(predict_table, predict_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c3dec-a32c-4123-a1cf-6f50fb338f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 1, root rows count 11871\n",
      "Completed iteration 2, root rows count 208\n",
      "Completed iteration 3, root rows count 97\n",
      "Completed iteration 4, root rows count 3\n",
      "Completed iteration 5, root rows count 0\n"
     ]
    }
   ],
   "source": [
    "clusters = linker.cluster_pairwise_predictions_at_threshold(\n",
    "    predictions,\n",
    "    threshold_match_probability=0.7,\n",
    "    pairwise_formatting=True,\n",
    "    filter_pairwise_format_for_clusters=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ad9f1-2ac2-4068-86d7-4adc9a3c4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.physical_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794845b-808d-4c38-abae-5ed916341e84",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db53b9f-a23a-4fb2-b4df-03460ca3ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.query(f\"select count(*) from {predict_table};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de38a7-d98b-4954-ace9-749ba2ead129",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.query(f\"select count(*) from {clusters.physical_name};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc32ad2-4ef4-41ad-ba8a-7fd1996b3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.query(\"pragma database_size;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da8589-740e-4b1a-9378-126dd42fa789",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.query(\"\"\"\n",
    "    select table_name\n",
    "    from information_schema.tables;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12259af6-6c4e-4197-86c1-f317950e5956",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99332ff3-5b26-42ae-abe4-8546fbb970ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.query(f\"\"\"\n",
    "    copy (\n",
    "        select\n",
    "            src_tbl.table_name as source,\n",
    "            src_id.unique_id as source_id,\n",
    "            cl.source_cluster,\n",
    "            tgt_tbl.table_name as target,\n",
    "            tgt_id.unique_id as target_id,\n",
    "            cl.target_cluster,\n",
    "            cl.match_probability\n",
    "        from (\n",
    "            select\n",
    "                source_dataset_l as source,\n",
    "                unique_id_l as source_id,\n",
    "                cluster_id_l as source_cluster,\n",
    "                source_dataset_r as target,\n",
    "                unique_id_r as target_id,\n",
    "                cluster_id_r as target_cluster,\n",
    "                match_probability\n",
    "            from\n",
    "                { clusters.physical_name }\n",
    "            union\n",
    "            select\n",
    "                source_dataset_r as source,\n",
    "                unique_id_r as source_id,\n",
    "                cluster_id_r as source_cluster,\n",
    "                source_dataset_l as target,\n",
    "                unique_id_l as target_id,\n",
    "                cluster_id_l as target_cluster,\n",
    "                match_probability\n",
    "            from\n",
    "                { clusters.physical_name }\n",
    "        ) cl\n",
    "        join table_alias_lookup src_tbl on\n",
    "            (cl.source = src_tbl.id)\n",
    "        join unique_id_lookup src_id on\n",
    "            (cl.source_id = src_id.id)\n",
    "        join table_alias_lookup tgt_tbl on\n",
    "            (cl.target = tgt_tbl.id)\n",
    "        join unique_id_lookup tgt_id on\n",
    "            (cl.target_id = tgt_id.id)\n",
    "    )\n",
    "    to '{CLUSTER_PATH.as_posix()}'\n",
    "    (format parquet);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d64340-3871-4081-b12d-5e0de37cc039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1294it [04:10,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 11.1 s, total: 1min 19s\n",
      "Wall time: 15min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "to_write = ds.dataset(CLUSTER_PATH)\n",
    "encoder = ArrowToPostgresBinaryEncoder(to_write.schema)\n",
    "pg_schema = encoder.schema()\n",
    "cols = [f'\"{col_name}\" {col.data_type.ddl()}' for col_name, col in pg_schema.columns]\n",
    "ddl = f\"create temp table data ({','.join(cols)})\"\n",
    "\n",
    "with psycopg.connect(\"postgres://\") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(ddl) \n",
    "        with cur.copy(\"copy data from stdin with (format binary)\") as copy:\n",
    "            copy.write(encoder.write_header())\n",
    "            for batch in tqdm(to_write.to_batches()):\n",
    "                copy.write(encoder.write_batch(batch))\n",
    "            copy.write(encoder.finish())\n",
    "        cur.execute(\"drop table if exists \\\"_user_eaf4fd9a\\\".\\\"lookup\\\"\")\n",
    "        cur.execute(\"\"\"\n",
    "            create table \\\"_user_eaf4fd9a\\\".\\\"lookup\\\" as \n",
    "            select * from data\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de763685-e345-4a7a-a85e-7cb4e7043fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<psycopg.Cursor [COMMAND_OK] [INTRANS] (host=datasets-1-aurora-2.cq9e4gwvtop7.eu-west-2.rds.amazonaws.com user=user_will_langdale_trade_gov_uk_crzjk database=public_datasets_1) at 0x7f65c14ab9e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<psycopg.Cursor [COMMAND_OK] [INTRANS] (host=datasets-1-aurora-2.cq9e4gwvtop7.eu-west-2.rds.amazonaws.com user=user_will_langdale_trade_gov_uk_crzjk database=public_datasets_1) at 0x7f65c14ab9e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<psycopg.Cursor [COMMAND_OK] [INTRANS] (host=datasets-1-aurora-2.cq9e4gwvtop7.eu-west-2.rds.amazonaws.com user=user_will_langdale_trade_gov_uk_crzjk database=public_datasets_1) at 0x7f65c14ab9e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<psycopg.Cursor [COMMAND_OK] [INTRANS] (host=datasets-1-aurora-2.cq9e4gwvtop7.eu-west-2.rds.amazonaws.com user=user_will_langdale_trade_gov_uk_crzjk database=public_datasets_1) at 0x7f65c14ab9e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with psycopg.connect(\"postgres://\") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"drop index if exists \\\"idx_wl_lookup_src_tgt\\\"\")\n",
    "        cur.execute(\"drop index if exists \\\"idx_wl_lookup_src_tgt_id\\\"\")\n",
    "        \n",
    "        cur.execute(\"create index \\\"idx_wl_lookup_src_tgt\\\" on \\\"_user_eaf4fd9a\\\".\\\"lookup\\\"(source, target)\")\n",
    "        cur.execute(\"create index \\\"idx_wl_lookup_src_tgt_id\\\" on \\\"_user_eaf4fd9a\\\".\\\"lookup\\\"(source_id, target_id)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b027eac-87f7-4db6-a2ad-5513bfe48c4c",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6f3c7-82b6-4c80-90f4-3a9259a0b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"select * from '{CLUSTER_PATH.as_posix()}' limit 5;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_matching",
   "language": "python",
   "name": "company_matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
