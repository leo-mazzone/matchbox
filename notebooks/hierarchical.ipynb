{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical algorithm optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rustworkx as rx\n",
    "from collections import Counter\n",
    "\n",
    "def verify_components(table) -> dict:\n",
    "    \"\"\"\n",
    "    Fast verification of connected components using rustworkx.\n",
    "    \n",
    "    Args:\n",
    "        table: PyArrow table with 'left', 'right' columns\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing basic component statistics\n",
    "    \"\"\"\n",
    "    # Create graph directly from arrays\n",
    "    graph = rx.PyDiGraph()\n",
    "    \n",
    "    # Add all unique nodes at once\n",
    "    unique_nodes = set(table['left'].to_numpy()) | set(table['right'].to_numpy())\n",
    "    graph.add_nodes_from(range(len(unique_nodes)))\n",
    "    \n",
    "    # Create node mapping and edges in one pass\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "    edges = [(node_to_idx[left], node_to_idx[right], prob) \n",
    "            for left, right, prob in zip(table['left'].to_numpy(), \n",
    "                                       table['right'].to_numpy(),\n",
    "                                       table['probability'].to_numpy())]\n",
    "    \n",
    "    # Add all edges at once\n",
    "    graph.add_edges_from(edges)\n",
    "    \n",
    "    # Get components and their sizes\n",
    "    components = rx.weakly_connected_components(graph)\n",
    "    component_sizes = Counter(len(component) for component in components)\n",
    "    \n",
    "    return {\n",
    "        'num_components': len(components),\n",
    "        'total_nodes': len(unique_nodes),\n",
    "        'total_edges': len(edges),\n",
    "        'component_sizes': component_sizes,\n",
    "        'min_component_size': min(component_sizes.keys()),\n",
    "        'max_component_size': max(component_sizes.keys())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max_possible_edges(n_nodes: int, num_components: int) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the maximum possible number of edges given n nodes split into k components.\n",
    "    \n",
    "    Args:\n",
    "        n_nodes: Total number of nodes\n",
    "        num_components: Number of components to split into\n",
    "        \n",
    "    Returns:\n",
    "        Maximum possible number of edges\n",
    "    \"\"\"\n",
    "    nodes_per_component = n_nodes // num_components\n",
    "    max_edges_per_component = nodes_per_component * nodes_per_component  # Complete bipartite graph\n",
    "    return max_edges_per_component * num_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import rustworkx as rx\n",
    "from typing import List, Tuple\n",
    "from decimal import Decimal\n",
    "\n",
    "def split_values_into_components(values: List[int], num_components: int) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split values into non-overlapping groups for each component.\n",
    "    \n",
    "    Args:\n",
    "        values: List of values to split\n",
    "        num_components: Number of components to create\n",
    "        \n",
    "    Returns:\n",
    "        List of arrays, one for each component\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    np.random.shuffle(values)\n",
    "    return np.array_split(values, num_components)\n",
    "\n",
    "\n",
    "def generate_arrow_data(\n",
    "    left_values: List[int],\n",
    "    right_values: List[int],\n",
    "    prob_range: Tuple[float, float],\n",
    "    num_components: int,\n",
    "    total_rows: int\n",
    ") -> pa.Table:\n",
    "    \"\"\"\n",
    "    Generate dummy arrow data with guaranteed isolated components.\n",
    "    \n",
    "    Args:\n",
    "        left_values: List of integers to use for left column\n",
    "        right_values: List of integers to use for right column\n",
    "        prob_range: Tuple of (min_prob, max_prob) to constrain probabilities\n",
    "        num_components: Number of distinct connected components to generate\n",
    "        total_rows: Total number of rows to generate\n",
    "    \n",
    "    Returns:\n",
    "        PyArrow Table with 'left', 'right', and 'probability' columns\n",
    "    \"\"\"\n",
    "    if len(left_values) < 2 or len(right_values) < 2:\n",
    "        raise ValueError(\"Need at least 2 possible values for both left and right\")\n",
    "    if num_components > min(len(left_values), len(right_values)):\n",
    "        raise ValueError(\"Cannot have more components than minimum of left/right values\")\n",
    "    \n",
    "    # Calculate maximum possible edges\n",
    "    min_nodes = min(len(left_values), len(right_values))\n",
    "    max_possible_edges = calculate_max_possible_edges(min_nodes, num_components)\n",
    "    \n",
    "    if total_rows > max_possible_edges:\n",
    "        raise ValueError(\n",
    "            f\"Cannot generate {total_rows:,} edges with {num_components:,} components. \"\n",
    "            f\"Maximum possible edges is {max_possible_edges:,} given {min_nodes:,} nodes. \"\n",
    "            \"Either increase the number of nodes, decrease the number of components, \"\n",
    "            \"or decrease the total edges requested.\"\n",
    "        )\n",
    "    \n",
    "    # Convert probability range to integers (60-80 for 0.60-0.80)\n",
    "    prob_min = int(prob_range[0] * 100)\n",
    "    prob_max = int(prob_range[1] * 100)\n",
    "    \n",
    "    # Split values into completely separate groups for each component\n",
    "    left_components = split_values_into_components(left_values, num_components)\n",
    "    right_components = split_values_into_components(right_values, num_components)\n",
    "    \n",
    "    # Calculate base number of edges per component\n",
    "    base_edges_per_component = total_rows // num_components\n",
    "    remaining_edges = total_rows % num_components\n",
    "    \n",
    "    all_edges = []\n",
    "    \n",
    "    # Generate edges for each component\n",
    "    for comp_idx in range(num_components):\n",
    "        comp_left_values = left_components[comp_idx]\n",
    "        comp_right_values = right_components[comp_idx]\n",
    "        \n",
    "        # Calculate edges for this component\n",
    "        edges_in_component = base_edges_per_component\n",
    "        if comp_idx < remaining_edges:  # Distribute remaining edges\n",
    "            edges_in_component += 1\n",
    "            \n",
    "        # Ensure basic connectivity within the component\n",
    "        base_edges = []\n",
    "        \n",
    "        # Create a spanning tree-like structure\n",
    "        for i in range(len(comp_left_values)):\n",
    "            base_edges.append((\n",
    "                comp_left_values[i],\n",
    "                comp_right_values[i % len(comp_right_values)],\n",
    "                np.random.randint(prob_min, prob_max + 1)\n",
    "            ))\n",
    "        \n",
    "        # Generate remaining random edges strictly within this component\n",
    "        remaining_edges = edges_in_component - len(base_edges)\n",
    "        if remaining_edges > 0:\n",
    "            random_lefts = np.random.choice(comp_left_values, size=remaining_edges)\n",
    "            random_rights = np.random.choice(comp_right_values, size=remaining_edges)\n",
    "            random_probs = np.random.randint(prob_min, prob_max + 1, size=remaining_edges)\n",
    "            \n",
    "            component_edges = base_edges + list(zip(random_lefts, random_rights, random_probs))\n",
    "        else:\n",
    "            component_edges = base_edges\n",
    "            \n",
    "        all_edges.extend(component_edges)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    lefts, rights, probs = zip(*all_edges)\n",
    "    \n",
    "    # Create PyArrow arrays\n",
    "    left_array = pa.array(lefts, type=pa.int64())\n",
    "    right_array = pa.array(rights, type=pa.int64())\n",
    "    decimal_probs = [Decimal(str(p/100)) for p in probs]\n",
    "    prob_array = pa.array(decimal_probs, type=pa.decimal128(precision=3, scale=2))\n",
    "    \n",
    "    return pa.table([left_array, right_array, prob_array],\n",
    "                   names=['left', 'right', 'probability'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components found: 10\n",
      "Total nodes: 20000\n",
      "Total edges: 1000009\n",
      "\n",
      "Component sizes:\n",
      "Size 2000: 10 components\n"
     ]
    }
   ],
   "source": [
    "left_values = list(range(10_000))\n",
    "right_values = list(range(10_000, 20_000))\n",
    "prob_range = (0.6, 0.8)\n",
    "num_components = 10\n",
    "total_rows = 1_000_000\n",
    "\n",
    "table = generate_arrow_data(\n",
    "    left_values=left_values,\n",
    "    right_values=right_values,\n",
    "    prob_range=prob_range,\n",
    "    num_components=num_components,\n",
    "    total_rows=total_rows\n",
    ")\n",
    "\n",
    "results = verify_components(table)\n",
    "print(f\"Number of components found: {results['num_components']}\")\n",
    "print(f\"Total nodes: {results['total_nodes']}\")\n",
    "print(f\"Total edges: {results['total_edges']}\")\n",
    "print(\"\\nComponent sizes:\")\n",
    "for size, count in sorted(results['component_sizes'].items()):\n",
    "    print(f\"Size {size}: {count} components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_values = list(range(int(2e7)))\n",
    "right_values = list(range(int(2e7), int(4e7)))\n",
    "prob_range = (0.7, 1.0)\n",
    "num_components = 200_000\n",
    "total_rows = int(1e8)\n",
    "\n",
    "table = generate_arrow_data(\n",
    "    left_values=left_values,\n",
    "    right_values=right_values,\n",
    "    prob_range=prob_range,\n",
    "    num_components=num_components,\n",
    "    total_rows=total_rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components found: 206763\n",
      "Total nodes: 40000000\n",
      "Total edges: 100000400\n",
      "\n",
      "Component sizes:\n",
      "Size 2: 6755 components\n",
      "Size 4: 8 components\n",
      "Size 194: 1 components\n",
      "Size 196: 124 components\n",
      "Size 198: 6520 components\n",
      "Size 200: 193355 components\n"
     ]
    }
   ],
   "source": [
    "results = verify_components(table)\n",
    "print(f\"Number of components found: {results['num_components']}\")\n",
    "print(f\"Total nodes: {results['total_nodes']}\")\n",
    "print(f\"Total edges: {results['total_edges']}\")\n",
    "print(\"\\nComponent sizes:\")\n",
    "for size, count in sorted(results['component_sizes'].items()):\n",
    "    print(f\"Size {size}: {count} components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of components found: 206763\n",
    "* Total nodes: 40000000\n",
    "* Total edges: 100000400\n",
    "\n",
    "Component sizes:\n",
    "* Size 2: 6755 components\n",
    "* Size 4: 8 components\n",
    "* Size 194: 1 components\n",
    "* Size 196: 124 components\n",
    "* Size 198: 6520 components\n",
    "* Size 200: 193355 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "pq.write_table(table, Path.cwd() / 'hierarchical_cc200k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_values = list(range(int(2e5)))\n",
    "right_values = list(range(int(2e5), int(4e5)))\n",
    "prob_range = (0.7, 1.0)\n",
    "num_components = 2_000\n",
    "total_rows = int(1e6)\n",
    "\n",
    "table2 = generate_arrow_data(\n",
    "    left_values=left_values,\n",
    "    right_values=right_values,\n",
    "    prob_range=prob_range,\n",
    "    num_components=num_components,\n",
    "    total_rows=total_rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components found: 2,080\n",
      "Total nodes: 400,000\n",
      "Total edges: 1,000,400\n",
      "\n",
      "Component sizes:\n",
      "Size 2: 80 components\n",
      "Size 196: 1 components\n",
      "Size 198: 78 components\n",
      "Size 200: 1,921 components\n"
     ]
    }
   ],
   "source": [
    "results2 = verify_components(table2)\n",
    "print(f\"Number of components found: {results2['num_components']:,}\")\n",
    "print(f\"Total nodes: {results2['total_nodes']:,}\")\n",
    "print(f\"Total edges: {results2['total_edges']:,}\")\n",
    "print(\"\\nComponent sizes:\")\n",
    "for size, count in sorted(results2['component_sizes'].items()):\n",
    "    print(f\"Size {size:,}: {count:,} components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of components found: 2,080\n",
    "* Total nodes: 400,000\n",
    "* Total edges: 1,000,400\n",
    "\n",
    "Component sizes:\n",
    "* Size 2: 80 components\n",
    "* Size 196: 1 components\n",
    "* Size 198: 78 components\n",
    "* Size 200: 1,921 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "pq.write_table(table2, Path.cwd() / 'hierarchical_cc2k.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "h2 = pq.read_table('hierarchical_cc2k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left: int64\n",
       "right: int64\n",
       "probability: decimal128(3, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan.\n",
    "\n",
    "* Find components and their sizes at lowest threshold (rustworkx)\n",
    "* Use this to dask.groupby the data for parallel per-component processing\n",
    "* Ensure we implement early stopping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_integers(*n: int) -> int:\n",
    "    \"\"\"\n",
    "    Combine n integers into a single negative integer.\n",
    "\n",
    "    Used to create a symmetric deterministic hash of two integers that populates the\n",
    "    range of integers efficiently and reduces the likelihood of collisions.\n",
    "\n",
    "    Aims to vectorise amazingly when used in Arrow.\n",
    "\n",
    "    Does this by:\n",
    "\n",
    "    * Using a Mersenne prime as a modulus\n",
    "    * Making negative integers positive with modulo, sped up with bitwise operations\n",
    "    * Combining using symmetric operations with coprime multipliers\n",
    "\n",
    "    Args:\n",
    "        *args: Variable number of integers to combine\n",
    "\n",
    "    Returns:\n",
    "        A negative integer\n",
    "    \"\"\"\n",
    "    P = 2147483647\n",
    "\n",
    "    total = 0\n",
    "    product = 1\n",
    "\n",
    "    for x in sorted(n):\n",
    "        x_pos = (x ^ (x >> 31)) - (x >> 31)\n",
    "        total = (total + x_pos) % P\n",
    "        product = (product * x_pos) % P\n",
    "\n",
    "    result = (31 * total + 37 * product) % P\n",
    "\n",
    "    return -result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080,\n",
       " pyarrow.Table\n",
       " left: int64\n",
       " right: int64\n",
       " probability: decimal128(3, 2)\n",
       " component: int64\n",
       " ----\n",
       " left: [[197413,116407,114551,160857,6412,...,39429,156175,197197,48177,121674]]\n",
       " right: [[326505,384163,344025,248700,258884,...,311452,278755,204144,357956,378111]]\n",
       " probability: [[1.00,1.00,1.00,1.00,1.00,...,0.70,0.70,0.70,0.70,0.70]]\n",
       " component: [[0,0,0,0,0,...,2079,2079,2079,2079,2079]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "import rustworkx as rx\n",
    "\n",
    "def attach_independent_components(table: pa.Table) -> pa.Table:\n",
    "    \"\"\"\n",
    "    Returns the original table with an additional 'component' column indicating\n",
    "    which connected component each edge belongs to.\n",
    "    \"\"\"\n",
    "    # Create dictionary array from sorted unique values\n",
    "    unique = pc.unique(\n",
    "        pa.concat_arrays([\n",
    "            table['left'].combine_chunks(),\n",
    "            table['right'].combine_chunks()\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # Get indices into unique array for graph construction\n",
    "    left_indices = pc.index_in(table['left'], unique)\n",
    "    right_indices = pc.index_in(table['right'], unique)\n",
    "    \n",
    "    # Create and process graph\n",
    "    n_nodes = len(unique)\n",
    "    n_edges = len(table)\n",
    "    \n",
    "    graph = rx.PyGraph(\n",
    "        node_count_hint=n_nodes,\n",
    "        edge_count_hint=n_edges\n",
    "    )\n",
    "    graph.add_nodes_from(range(n_nodes))\n",
    "\n",
    "    edges = tuple(zip(left_indices.to_numpy(), right_indices.to_numpy()))\n",
    "    graph.add_edges_from_no_data(edges)\n",
    "    \n",
    "    # Get components and create mapping array\n",
    "    components = rx.connected_components(graph)\n",
    "    \n",
    "    # Convert components to numpy arrays\n",
    "    component_indices = np.concatenate([np.array(list(c)) for c in components])\n",
    "    component_labels = np.repeat(np.arange(len(components)), [len(c) for c in components])\n",
    "    \n",
    "    # Create mapping array and fill with component labels\n",
    "    node_to_component = np.zeros(len(unique), dtype=np.int64)\n",
    "    node_to_component[component_indices] = component_labels\n",
    "    \n",
    "    # Use the indices we already have to map back to components  \n",
    "    edge_components = pa.array(node_to_component[left_indices.to_numpy()])\n",
    "    \n",
    "    return table.append_column('component', edge_components).sort_by(\n",
    "        [('component', 'ascending'), ('probability', 'descending')]\n",
    "    )\n",
    "\n",
    "cc = attach_independent_components(table2)\n",
    "len(pc.unique(cc.column('component'))), cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         29986 function calls in 0.775 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 35 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.874    0.437 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3541(run_code)\n",
      "        2    0.000    0.000    0.874    0.437 {built-in method builtins.exec}\n",
      "        1    0.373    0.373    0.775    0.775 /var/folders/14/6nvsrw1n2ls1xncz_bvy2x8m0000gq/T/ipykernel_25768/4265471472.py:6(find_independent_components)\n",
      "        1    0.102    0.102    0.103    0.103 {connected_components}\n",
      "        1    0.097    0.097    0.097    0.097 {method 'add_edges_from_no_data' of 'rustworkx.PyGraph' objects}\n",
      "        2    0.090    0.045    0.090    0.045 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/pyarrow/compute.py:249(wrapper)\n",
      "        1    0.074    0.074    0.074    0.074 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/pyarrow/compute.py:239(wrapper)\n",
      "     2850    0.009    0.000    0.025    0.000 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py:775(_clean_thread_parent_frames)\n",
      "        1    0.013    0.013    0.013    0.013 {method 'add_nodes_from' of 'rustworkx.PyGraph' objects}\n",
      "     1425    0.006    0.000    0.009    0.000 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py:790(<setcomp>)\n",
      "     1425    0.005    0.000    0.006    0.000 /Users/willlangdale/.pyenv/versions/3.11.8/lib/python3.11/threading.py:1501(enumerate)\n",
      "    11400    0.003    0.000    0.003    0.000 /Users/willlangdale/.pyenv/versions/3.11.8/lib/python3.11/threading.py:1168(ident)\n",
      "     5700    0.001    0.000    0.001    0.000 {method 'keys' of 'dict' objects}\n",
      "     2850    0.001    0.000    0.001    0.000 {method 'values' of 'dict' objects}\n",
      "     1425    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "     2853    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/willlangdale/.pyenv/versions/3.11.8/lib/python3.11/codeop.py:120(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/pyarrow/compute.py:216(_handle_options)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/willlangdale/.pyenv/versions/3.11.8/lib/python3.11/contextlib.py:299(helper)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x15e22c1d0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "# Profile the function\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "components = attach_independent_components(table2)\n",
    "pr.disable()\n",
    "\n",
    "# Print stats sorted by cumulative time\n",
    "ps = pstats.Stats(pr).sort_stats(SortKey.CUMULATIVE)\n",
    "ps.print_stats(20)  # Show top 20 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3411228 function calls in 121.198 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 48 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000  139.163   69.581 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3541(run_code)\n",
      "        2    0.001    0.000  139.162   69.581 {built-in method builtins.exec}\n",
      "        1   47.532   47.532  121.195  121.195 /var/folders/14/6nvsrw1n2ls1xncz_bvy2x8m0000gq/T/ipykernel_25768/2801194547.py:1(find_independent_components)\n",
      "        1   24.123   24.123   24.123   24.123 {method 'add_edges_from_no_data' of 'rustworkx.PyGraph' objects}\n",
      "        1   18.713   18.713   18.731   18.731 {connected_components}\n",
      "        2   14.375    7.187   14.375    7.187 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/pyarrow/compute.py:249(wrapper)\n",
      "        1    7.661    7.661    7.661    7.661 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/pyarrow/compute.py:239(wrapper)\n",
      "        1    1.303    1.303    4.041    4.041 /var/folders/14/6nvsrw1n2ls1xncz_bvy2x8m0000gq/T/ipykernel_25768/2801194547.py:35(<listcomp>)\n",
      "   206763    2.738    0.000    2.738    0.000 {built-in method numpy.array}\n",
      "   285488    0.966    0.000    2.629    0.000 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py:775(_clean_thread_parent_frames)\n",
      "        1    1.879    1.879    1.879    1.879 {method 'add_nodes_from' of 'rustworkx.PyGraph' objects}\n",
      "   142744    0.579    0.000    0.912    0.000 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py:790(<setcomp>)\n",
      "   142744    0.527    0.000    0.629    0.000 /Users/willlangdale/.pyenv/versions/3.11.8/lib/python3.11/threading.py:1501(enumerate)\n",
      "  1141952    0.333    0.000    0.333    0.000 /Users/willlangdale/.pyenv/versions/3.11.8/lib/python3.11/threading.py:1168(ident)\n",
      "        1    0.001    0.001    0.167    0.167 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:467(repeat)\n",
      "        1    0.000    0.000    0.166    0.166 /Users/willlangdale/DS/matchbox/.venv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:51(_wrapfunc)\n",
      "        1    0.166    0.166    0.166    0.166 {method 'repeat' of 'numpy.ndarray' objects}\n",
      "   570976    0.082    0.000    0.082    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.053    0.053    0.073    0.073 /var/folders/14/6nvsrw1n2ls1xncz_bvy2x8m0000gq/T/ipykernel_25768/2801194547.py:36(<listcomp>)\n",
      "   285488    0.053    0.000    0.053    0.000 {method 'values' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x16d1a8190>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "# Profile the function\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "_ = attach_independent_components(table)\n",
    "pr.disable()\n",
    "\n",
    "# Print stats sorted by cumulative time\n",
    "ps = pstats.Stats(pr).sort_stats(SortKey.CUMULATIVE)\n",
    "ps.print_stats(20)  # Show top 20 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process a single component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def component_to_hierarchy(key: str | int | tuple, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert pairwise probabilities into a hierarchical representation.\n",
    "    Assumes data is pre-sorted by probability descending.\n",
    "    \n",
    "    Args:\n",
    "        key: Group key (ignored in this implementation)\n",
    "        df: DataFrame with columns ['left', 'right', 'probability']\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns ['parent', 'child', 'probability'] representing hierarchical merges\n",
    "    \"\"\"\n",
    "    hierarchy: list[tuple[int, int, float]] = []\n",
    "    ultimate_parents: dict[int, set[int]] = defaultdict(set)\n",
    "    \n",
    "    # Process each probability threshold\n",
    "    for prob in df['probability'].unique():\n",
    "        # Process pairs at this threshold\n",
    "        current_pairs = df[df['probability'] == prob]\n",
    "        \n",
    "        for _, row in current_pairs.iterrows():\n",
    "            left, right = row['left'], row['right']\n",
    "            \n",
    "            # Skip if already in same component\n",
    "            if ultimate_parents[left] & ultimate_parents[right]:\n",
    "                continue\n",
    "                \n",
    "            # Create merged node\n",
    "            merged = combine_integers(left, right)\n",
    "            \n",
    "            # Add relationships to hierarchy\n",
    "            hierarchy.extend([\n",
    "                (merged, left, prob),\n",
    "                (merged, right, prob)\n",
    "            ])\n",
    "            \n",
    "            # Update parent tracking\n",
    "            ultimate_parents[left].add(merged)\n",
    "            ultimate_parents[right].add(merged)\n",
    "            \n",
    "            # Find all related nodes through shared parents\n",
    "            parents_to_check = ultimate_parents[left] | ultimate_parents[right]\n",
    "            related_nodes = {\n",
    "                node \n",
    "                for node, parents in ultimate_parents.items() \n",
    "                if parents & parents_to_check and node not in (left, right)\n",
    "            }\n",
    "            \n",
    "            if related_nodes:\n",
    "                # Create new merged node for all related components\n",
    "                super_merged = combine_integers(merged, *related_nodes)\n",
    "                \n",
    "                # Add relationships\n",
    "                hierarchy.extend(\n",
    "                    (super_merged, child, prob)\n",
    "                    for child in (merged, *related_nodes)\n",
    "                )\n",
    "                \n",
    "                # Update parent tracking for all children\n",
    "                new_parents = {super_merged}\n",
    "                for child in (left, right, *related_nodes):\n",
    "                    ultimate_parents[child] = new_parents\n",
    "            else:\n",
    "                # Just update the two merged nodes\n",
    "                new_parents = {merged}\n",
    "                ultimate_parents[left] = new_parents\n",
    "                ultimate_parents[right] = new_parents\n",
    "        \n",
    "        # Early stopping - check if everything is merged\n",
    "        if len(set.union(*ultimate_parents.values())) == 1:\n",
    "            break\n",
    "    \n",
    "    # Convert to DataFrame, already sorted by probability descending\n",
    "    return pd.DataFrame(hierarchy, columns=['parent', 'child', 'probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>probability</th>\n",
       "      <th>component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197413</td>\n",
       "      <td>326505</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116407</td>\n",
       "      <td>384163</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114551</td>\n",
       "      <td>344025</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160857</td>\n",
       "      <td>248700</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6412</td>\n",
       "      <td>258884</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>109907</td>\n",
       "      <td>399129</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>194530</td>\n",
       "      <td>385858</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5985</td>\n",
       "      <td>212599</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>19131</td>\n",
       "      <td>294811</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>193341</td>\n",
       "      <td>224447</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       left   right probability  component\n",
       "0    197413  326505        1.00          0\n",
       "1    116407  384163        1.00          0\n",
       "2    114551  344025        1.00          0\n",
       "3    160857  248700        1.00          0\n",
       "4      6412  258884        1.00          0\n",
       "..      ...     ...         ...        ...\n",
       "495  109907  399129        0.70          0\n",
       "496  194530  385858        0.70          0\n",
       "497    5985  212599        0.70          0\n",
       "498   19131  294811        0.70          0\n",
       "499  193341  224447        0.70          0\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc\n",
    "# Convert the Arrow table to a Pandas DataFrame\n",
    "df = cc.to_pandas()\n",
    "\n",
    "# Filter the DataFrame where component is 0\n",
    "cc_0 = df[df['component'] == 0]\n",
    "cc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>child</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1193661193</td>\n",
       "      <td>197413</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1193661193</td>\n",
       "      <td>326505</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1065816097</td>\n",
       "      <td>116407</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1065816097</td>\n",
       "      <td>384163</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2131390865</td>\n",
       "      <td>114551</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>-28774449</td>\n",
       "      <td>119799</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>-28774449</td>\n",
       "      <td>290808</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9343</th>\n",
       "      <td>-28774449</td>\n",
       "      <td>375290</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9344</th>\n",
       "      <td>-28774449</td>\n",
       "      <td>154622</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>-28774449</td>\n",
       "      <td>246271</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9346 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          parent   child probability\n",
       "0    -1193661193  197413        1.00\n",
       "1    -1193661193  326505        1.00\n",
       "2    -1065816097  116407        1.00\n",
       "3    -1065816097  384163        1.00\n",
       "4    -2131390865  114551        1.00\n",
       "...          ...     ...         ...\n",
       "9341   -28774449  119799        0.82\n",
       "9342   -28774449  290808        0.82\n",
       "9343   -28774449  375290        0.82\n",
       "9344   -28774449  154622        0.82\n",
       "9345   -28774449  246271        0.82\n",
       "\n",
       "[9346 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_to_hierarchy(0, cc_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
